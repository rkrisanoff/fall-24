В качестве датасета были выбраны данные с видами стекла и их химическими характеристиками: https://www.kaggle.com/datasets/uciml/glass?resource=download. Датасет был выбран из-за его небольшого размера, а также из-за наличия только непрерывных признаков, что хорошо подходит под KNN.
Сначала был проведён разведочный анализ данных, в результате которого не было выявлено пропусков и других аномалий. Для графического отображения положений объектов был применён метод главных компонент. Результат изображён на графике:
![PCA](https://github.com/user-attachments/assets/f71e14e2-3c18-403a-aa64-93cace0d8bc6)
Далее был написан класс, реализующий:
1) Метод k ближайших соседей с окном Парзена переменной ширины, способный вычислятьрасстояние между объектами метриками L1 и Евклида
2) Метод LOO для вычисления точности классификации при фиксированных гиперпараметрах
3) Вывод графика эмпирических рисков для разных значений параметра k

Данный класс был апробирован на датасете, в результате чего было получено 2 графика эмпирических рисков для метрик L2 и L1 соответственно:
![Эмпирический риск L2](https://github.com/user-attachments/assets/adcc1b14-1caf-4b42-b3e0-ff1d70d94b97)
![Эмпирический риск L1](https://github.com/user-attachments/assets/41a83167-017f-4eba-a0df-fe4b4c145fae)

Далее оптимальное число k для обеих метрик было сравнено на тестовой выборке, в результате чего по итогу была выбрана метрика Евклида с k=4.Точность оказалась равна 70,7%.
Далее было произведено сравнение с эталонной реализацией алгоритма из sklearn. Время выполнения написанного алгоритма оказалось меньше, чем эталонного. Несмотря на то, что в эталонной реализации не было реализовано окно Парзена, точности алгоритмов с одинаковыми гиперпараметрами совпали, хотя ответы на 14% расходились.
